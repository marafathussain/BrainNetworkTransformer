{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "from preprocess_data import Reader\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import deepdish as dd\n",
    "import warnings\n",
    "import os.path as osp\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "        return True\n",
    "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '/home/ch225256/Data'\n",
    "data_folder = os.path.join(root_folder, 'ABIDE_pcp/cpac/filt_noglobal/')\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "pipeline = 'cpac'\n",
    "atlas = 'cc200'\n",
    "download = True\n",
    "id_file_path = 'subject_IDs.txt'\n",
    "\n",
    "# Files to fetch\n",
    "\n",
    "files = ['rois_' + atlas]\n",
    "\n",
    "# Download database files\n",
    "if download == True:\n",
    "    abide = datasets.fetch_abide_pcp(data_dir=root_folder, pipeline=pipeline,\n",
    "                                        band_pass_filtering=True, global_signal_regression=False, derivatives=files,\n",
    "                                        quality_checked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subject-wise foldering and extracting correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '/home/ch225256/Data'\n",
    "id_file_path = 'subject_IDs.txt'\n",
    "reader = Reader(root_folder, id_file_path)\n",
    "data_folder = os.path.join(root_folder, 'ABIDE_pcp/cpac/filt_noglobal/')\n",
    "\n",
    "pipeline = 'cpac'\n",
    "atlas = 'cc200'\n",
    "files = ['rois_' + atlas]\n",
    "filemapping = {'func_preproc': 'func_preproc.nii.gz',\n",
    "                files[0]: files[0] + '.1D'}\n",
    "\n",
    "#phenotype_file = os.path.join(root_folder, \"ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "#phenotype_df = pd.read_csv(phenotype_file, index_col=0)\n",
    "\n",
    "temp = '/home/ch225256/Data/subject_IDs.txt'\n",
    "subject_IDs = np.genfromtxt(temp, dtype=str)\n",
    "\n",
    "# Create a folder for each subject\n",
    "for s, fname in zip(subject_IDs, reader.fetch_filenames(subject_IDs, files[0], atlas)):\n",
    "    subject_folder = os.path.join(data_folder, s)\n",
    "    if not os.path.exists(subject_folder):\n",
    "        os.mkdir(subject_folder)\n",
    "\n",
    "    # Get the base filename for each subject\n",
    "    base = fname.split(files[0])[0]\n",
    "\n",
    "    # Move each subject file to the subject folder\n",
    "    for fl in files:\n",
    "        if not os.path.exists(os.path.join(subject_folder, base + filemapping[fl])):\n",
    "            shutil.move(base + filemapping[fl], subject_folder)\n",
    "\n",
    "time_series = reader.get_timeseries(subject_IDs, atlas)\n",
    "\n",
    "# Compute and save connectivity matrices\n",
    "reader.subject_connectivity(time_series, subject_IDs, atlas, 'correlation')\n",
    "reader.subject_connectivity(time_series, subject_IDs, atlas, 'partial correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation matrix generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_path = '/home/ch225256/Data'\n",
    "data_folder = os.path.join(root_path, 'ABIDE_pcp/cpac/filt_noglobal/')\n",
    "\n",
    "params = dict()\n",
    "\n",
    "params['seed'] = 123  # seed for random initialization\n",
    "id_file_path = 'subject_IDs.txt'\n",
    "\n",
    "# Algorithm choice\n",
    "params['atlas'] = 'cc200'  # Atlas for network construction\n",
    "atlas = 'cc200'  # Atlas for network construction (node definition)\n",
    "\n",
    "reader = Reader(root_path, id_file_path)\n",
    "# Get subject IDs and class labels\n",
    "temp = '/home/ch225256/Data/subject_IDs.txt'\n",
    "subject_IDs = np.genfromtxt(temp, dtype=str)\n",
    "labels = reader.get_subject_score(subject_IDs, score='DX_GROUP')\n",
    "\n",
    "# Number of subjects and classes for binary classification\n",
    "num_classes = 2\n",
    "num_subjects = len(subject_IDs)\n",
    "params['n_subjects'] = num_subjects\n",
    "\n",
    "# Initialise variables for class labels and acquisition sites\n",
    "# 1 is autism, 2 is control\n",
    "y_data = np.zeros([num_subjects, num_classes]) # n x 2\n",
    "y = np.zeros([num_subjects, 1]) # n x 1\n",
    "\n",
    "# Get class labels for all subjects\n",
    "for i in range(num_subjects):\n",
    "    y_data[i, int(labels[subject_IDs[i]]) - 1] = 1\n",
    "    y[i] = int(labels[subject_IDs[i]])\n",
    "\n",
    "# Compute feature vectors (vectorized connectivity networks)\n",
    "fea_corr = reader.get_networks(subject_IDs, iter_no='', kind='correlation', atlas_name=atlas) #(1035, 200, 200)\n",
    "fea_pcorr = reader.get_networks(subject_IDs, iter_no='', kind='partial correlation', atlas_name=atlas) #(1035, 200, 200)\n",
    "\n",
    "if not os.path.exists(os.path.join(data_folder,'raw')):\n",
    "    os.makedirs(os.path.join(data_folder,'raw'))\n",
    "for i, subject in enumerate(subject_IDs):\n",
    "    dd.io.save(os.path.join(data_folder,'raw',subject+'.h5'),{'corr':fea_corr[i],'pcorr':fea_pcorr[i],'label':(y[i]-1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/home/ch225256/Data'\n",
    "data_dir =  os.path.join(root_path, 'ABIDE_pcp/cpac/filt_noglobal/raw')\n",
    "timeseires = os.path.join(root_path, 'ABIDE_pcp/cpac/filt_noglobal/')\n",
    "\n",
    "meta_file = os.path.join(root_path, \"ABIDE_pcp/Phenotypic_V1_0b_preprocessed1.csv\")\n",
    "meta_file = pd.read_csv(meta_file, header=0)\n",
    "\n",
    "id2site = meta_file[[\"subject\", \"SITE_ID\"]]\n",
    "\n",
    "# pandas to map\n",
    "id2site = id2site.set_index(\"subject\")\n",
    "id2site = id2site.to_dict()['SITE_ID']\n",
    "\n",
    "times = []\n",
    "piq = []\n",
    "viq = []\n",
    "fiq = []\n",
    "labels = []\n",
    "pcorrs = []\n",
    "corrs = []\n",
    "site_list = []\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    if osp.isfile(osp.join(data_dir, f)):\n",
    "        fname = f.split('.')[0]\n",
    "        site = id2site[int(fname)]\n",
    "        \n",
    "        fiq_ = meta_file.loc[meta_file['subject'] == int(fname), 'FIQ'].values[0]\n",
    "        viq_ = meta_file.loc[meta_file['subject'] == int(fname), 'VIQ'].values[0]\n",
    "        piq_ = meta_file.loc[meta_file['subject'] == int(fname), 'PIQ'].values[0]\n",
    "        \n",
    "        if np.isnan(fiq_) or np.isnan(viq_) or np.isnan(piq_):\n",
    "            continue\n",
    "        elif fiq_ > 200 or fiq_ < 20:\n",
    "            continue\n",
    "        elif viq_ > 200 or viq_ < 20:\n",
    "            continue\n",
    "        elif piq_ > 200 or piq_ < 20:\n",
    "            continue\n",
    "        \n",
    "        files = os.listdir(osp.join(timeseires, fname))\n",
    "\n",
    "        file = list(filter(lambda x: x.endswith(\"1D\"), files))[0]\n",
    "\n",
    "        time = np.loadtxt(osp.join(timeseires, fname, file), skiprows=0).T\n",
    "\n",
    "        if time.shape[1] < 100:\n",
    "            continue\n",
    "\n",
    "        temp = dd.io.load(osp.join(data_dir,  f))\n",
    "        pcorr = temp['pcorr'][()]\n",
    "\n",
    "        pcorr[pcorr == float('inf')] = 0\n",
    "\n",
    "        att = temp['corr'][()]\n",
    "\n",
    "        att[att == float('inf')] = 0\n",
    "\n",
    "        label = temp['label']\n",
    "\n",
    "        times.append(time[:,:100])\n",
    "        labels.append(label[0])\n",
    "        fiq.append(fiq_)\n",
    "        viq.append(viq_)\n",
    "        piq.append(piq_)\n",
    "        corrs.append(att)\n",
    "        pcorrs.append(pcorr)\n",
    "        site_list.append(site)\n",
    "\n",
    "np.save(Path(root_path)/'ABIDE_pcp/abide.npy', {'timeseires': np.array(times), \"label\": np.array(labels), \"fiq\": np.array(fiq), \"viq\": np.array(viq), \"piq\": np.array(piq), \"corr\": np.array(corrs),\"pcorr\": np.array(pcorrs), 'site': np.array(site_list)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
